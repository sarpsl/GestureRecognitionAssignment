{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwYBFSxzfSm0"
      },
      "source": [
        "# Gesture Recognition\n",
        "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <font color='blue'>Index</font>\n",
        "- <font color='blue'>1. Initial Steps</font>\n",
        "\t- <font color='blue'>1.1 Imports</font>\n",
        "\t- <font color='blue'>1.2 Random Seeds</font>\n",
        "\t- <font color='blue'>1.3 Google Drive Connect</font>\n",
        "\t- <font color='blue'>1.4 Setting Paths</font>\n",
        "\t- <font color='blue'>1.5 Defining Generator</font>\n",
        "\t- <font color='blue'>1.6 Listing File Counts</font>\n",
        "- <font color='blue'>2. Models</font>\n",
        "\t- <font color='blue'>2.1 Model 1 - </font>\n",
        "\t\t- <font color='blue'>2.1.1 Design, Compile & Summary</font>\n",
        "\t\t- <font color='blue'>2.1.2 Model Training</font>\n",
        "\t\t- <font color='blue'>2.1.3 Accuracy & Remarks</font>\n",
        "\t\t- <font color='blue'>2.1.4 Next Actions</font>\n",
        "\t- <font color='blue'>2.2 Model 2 - </font>\n",
        "\t\t- <font color='blue'>2.2.1 Design, Compile & Summary</font>\n",
        "\t\t- <font color='blue'>2.2.2 Model Training</font>\n",
        "\t\t- <font color='blue'>2.2.3 Accuracy & Remarks</font>\n",
        "\t\t- <font color='blue'>2.2.4 Next Actions</font>\n",
        "\t- <font color='blue'>2.3 Model 3 - </font>\n",
        "\t\t- <font color='blue'>2.3.1 Design, Compile & Summary</font>\n",
        "\t\t- <font color='blue'>2.3.2 Model Training</font>\n",
        "\t\t- <font color='blue'>2.3.3 Accuracy & Remarks</font>\n",
        "\t\t- <font color='blue'>2.3.4 Next Actions</font>\n",
        "\t- <font color='blue'>2.4 Model 4 - </font>\n",
        "\t\t- <font color='blue'>2.4.1 Design, Compile & Summary</font>\n",
        "\t\t- <font color='blue'>2.4.2 Model Training</font>\n",
        "\t\t- <font color='blue'>2.4.3 Accuracy & Remarks</font>\n",
        "\t\t- <font color='blue'>2.4.4 Next Actions</font>\n",
        "\t- <font color='blue'>2.5 Model 5 - </font>\n",
        "\t\t- <font color='blue'>2.5.1 Design, Compile & Summary</font>\n",
        "\t\t- <font color='blue'>2.5.2 Model Training</font>\n",
        "\t\t- <font color='blue'>2.5.3 Accuracy & Remarks</font>\n",
        "\t\t- <font color='blue'>2.5.4 Next Actions</font>\n",
        "\t- <font color='blue'>2.6 Model 6 - </font>\n",
        "\t\t- <font color='blue'>2.6.1 Design, Compile & Summary</font>\n",
        "\t\t- <font color='blue'>2.6.2 Model Training</font>\n",
        "\t\t- <font color='blue'>2.6.3 Accuracy & Remarks</font>\n",
        "\t\t- <font color='blue'>2.6.4 Next Actions</font>\n",
        "- <font color='blue'>3. Conclusion & Final Selection</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <font color='blue'>1. Initial Steps</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <font color='blue'>1.1 Imports</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yAotwUfcfSm1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import imageio.v2 as imageio\n",
        "from imageio.v2 import imread\n",
        "from skimage.transform import resize\n",
        "import datetime\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
        "from keras.layers import Conv3D, MaxPooling3D\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import optimizers\n",
        "\n",
        "from keras.applications import mobilenet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <font color='blue'>1.2 Random Seeds</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D24Jv6apfSm3"
      },
      "source": [
        "We set the random seed so that the results don't vary drastically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aiewGHh_fSm3"
      },
      "outputs": [],
      "source": [
        "np.random.seed(30)\n",
        "import random as rn\n",
        "rn.seed(30)\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGLD34vMfSm3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <font color='blue'>1.3 Google Drive Connect</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkaxqxbDfSm3",
        "outputId": "0ec2cb13-97be-49ee-ce4f-dd6caea1beb1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <font color='blue'>1.4 Setting Paths</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HG7Zs-L-g7LF"
      },
      "outputs": [],
      "source": [
        "train_doc = np.random.permutation(open('/content/gdrive/My Drive/Personal/upGrad/MS/Recurrent Neural Networks/Project_data/train.csv').readlines())\n",
        "val_doc = np.random.permutation(open('/content/gdrive/My Drive/Personal/upGrad/MS/Recurrent Neural Networks/Project_data/val.csv').readlines())\n",
        "\n",
        "# train_doc = np.random.permutation(open('G:\\\\My Drive\\\\Personal\\\\upGrad\\\\MS\\\\Recurrent Neural Networks\\\\Project_data\\\\train.csv').readlines())\n",
        "# val_doc = np.random.permutation(open('G:\\\\My Drive\\\\Personal\\\\upGrad\\\\MS\\\\Recurrent Neural Networks\\\\Project_data\\\\val.csv').readlines())\n",
        "\n",
        "batch_size = 64 #experiment with the batch size 16, 32, 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <font color='blue'>1.5 Defining Generator</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJtMUnfmfSm4"
      },
      "source": [
        "## Generator\n",
        "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "36MY7krNfSm4"
      },
      "outputs": [],
      "source": [
        "def generator(source_path, folder_list, batch_size, img_idx, image_height, image_width):\n",
        "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
        "    # img_idx = [1,4,7,10,13,16,19,22,25,28] #create a list of image numbers you want to use for a particular video\n",
        "    while True:\n",
        "        t = np.random.permutation(folder_list)\n",
        "        num_batches = int(len(t)/batch_size) # calculate the number of batches\n",
        "        # left over batches which should be handled separately\n",
        "        leftover_batches = len(t) - num_batches * batch_size\n",
        "\n",
        "        for batch in range(num_batches): # we iterate over the number of batches\n",
        "            batch_data = np.zeros((batch_size, len(img_idx), image_height, image_width, 3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
        "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
        "            for folder in range(batch_size): # iterate over the batch_size\n",
        "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
        "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
        "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "\n",
        "                    #crop the images and resize them. Note that the images are of 2 different shape\n",
        "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
        "                    image = resize(image, (image_height, image_width))\n",
        "                    batch_data[folder,idx,:,:,0] = (image[:,:,0]) - 104\n",
        "                    batch_data[folder,idx,:,:,1] = (image[:,:,1]) - 117\n",
        "                    batch_data[folder,idx,:,:,2] = (image[:,:,2]) - 123\n",
        "\n",
        "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
        "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
        "\n",
        "\n",
        "        # write the code for the remaining data points which are left after full batches\n",
        "        # write the code for the remaining data points which are left after full batches\n",
        "        if leftover_batches != 0:\n",
        "            for batch in range(num_batches):\n",
        "                # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
        "                batch_data = np.zeros((batch_size,len(img_idx),image_height, image_width,3))\n",
        "                # batch_labels is the one hot representation of the output: 10 videos with 5 columns as classes\n",
        "                batch_labels = np.zeros((batch_size,5))\n",
        "                for folder in range(batch_size): # iterate over the batch_size\n",
        "                    imgs = os.listdir(source_path +'/'+t[batch * batch_size + folder].split(';')[0])\n",
        "                    for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
        "\n",
        "                        image = imageio.imread(source_path +'/'+t[batch * batch_size + folder].split(';')[0] +'/'+imgs[item]).astype(np.float32)\n",
        "                        image = resize(image, (image_height,image_width))\n",
        "\n",
        "                        batch_data[folder,idx,:,:,0] = (image[:,:,0]) - 104\n",
        "                        batch_data[folder,idx,:,:,1] = (image[:,:,1]) - 117\n",
        "                        batch_data[folder,idx,:,:,2] = (image[:,:,2]) - 123\n",
        "\n",
        "                    #Fill the one hot encoding stuff where we maintain the label\n",
        "                    batch_labels[folder, int(t[batch * batch_size + folder].split(';')[2])] = 1\n",
        "                yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUEXzkB6fSm4"
      },
      "source": [
        "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <font color='blue'>1.6 Listing File Counts</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsV9JJxIfSm4",
        "outputId": "56372afe-17a5-4d91-c759-b4a3f9936396"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# training sequences = 663\n",
            "# validation sequences = 100\n",
            "# epochs = 15\n"
          ]
        }
      ],
      "source": [
        "curr_dt_time = datetime.datetime.now()\n",
        "train_path = '/content/gdrive/My Drive/Personal/upGrad/MS/Recurrent Neural Networks/Project_data/train'\n",
        "val_path = '/content/gdrive/My Drive/Personal/upGrad/MS/Recurrent Neural Networks/Project_data/val'\n",
        "model_path_prefix = '/content/gdrive/My Drive/Personal/upGrad/MS/Recurrent Neural Networks/Models/'\n",
        "# train_path = 'G:\\\\My Drive\\\\Personal\\\\upGrad\\\\MS\\\\Recurrent Neural Networks\\\\Project_data\\\\train'\n",
        "# val_path = 'G:\\\\My Drive\\\\Personal\\\\upGrad\\\\MS\\\\Recurrent Neural Networks\\\\Project_data\\\\val'\n",
        "# model_path_prefix = 'C:\\\\Temp\\\\RNN\\\\'\n",
        "num_train_sequences = len(train_doc)\n",
        "print('# training sequences =', num_train_sequences)\n",
        "num_val_sequences = len(val_doc)\n",
        "print('# validation sequences =', num_val_sequences)\n",
        "num_epochs = 15 # choose the number of epochs\n",
        "print ('# epochs =', num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i26PWoagGCPz",
        "outputId": "b6458f6e-2bc1-4f7f-9049-2cb211739d78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Source path =  G:\\My Drive\\Personal\\upGrad\\MS\\Recurrent Neural Networks\\Project_data\\train ; batch size = 1\n"
          ]
        }
      ],
      "source": [
        "img_idx = list(range(1,30,3))\n",
        "image_height = 50\n",
        "image_width = 50\n",
        "batch_size = 1\n",
        "test_gen = generator(train_path, train_doc, batch_size, img_idx, image_height, image_width)\n",
        "d = next(test_gen)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <font color='blue'>2. Models</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <font color='blue'>2.1 Model 1 - </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <font color='blue'>2.1.1 Design, Compile & Summary</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbYgj_BpfSm5",
        "outputId": "7e357750-e20e-43a3-b699-e9d7ae30425c",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\ASyed\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\ASyed\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d (Conv3D)             (None, 10, 50, 50, 16)    1312      \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3  (None, 5, 25, 25, 16)     0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 5, 25, 25, 16)     64        \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 5, 25, 25, 32)     13856     \n",
            "                                                                 \n",
            " max_pooling3d_1 (MaxPoolin  (None, 2, 12, 12, 32)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 2, 12, 12, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_2 (Conv3D)           (None, 2, 12, 12, 64)     55360     \n",
            "                                                                 \n",
            " max_pooling3d_2 (MaxPoolin  (None, 1, 6, 6, 64)       0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 1, 6, 6, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2304)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               295040    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 366661 (1.40 MB)\n",
            "Trainable params: 366437 (1.40 MB)\n",
            "Non-trainable params: 224 (896.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "img_idx = list(range(1,30,3))\n",
        "frames = len(img_idx)\n",
        "image_height = 50\n",
        "image_width = 50\n",
        "batch_size = 1\n",
        "num_classes = 5\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv3D(16, (3,3,3), padding='same', input_shape=(frames, image_height, image_width, 3), activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(32, (3,3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(64, (3,3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "optimiser = \"adam\"\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <font color='blue'>2.1.2 Model Training</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ut5YMGEfSm6"
      },
      "source": [
        "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAukElrPfSm6",
        "outputId": "bde51969-2835-49ec-85f7-94d5ab8c6502"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Source path =  G:\\My Drive\\Personal\\upGrad\\MS\\Recurrent Neural Networks\\Project_data\\train ; batch size = 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ASyed\\AppData\\Local\\Temp\\ipykernel_46732\\4257311695.py:26: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\ASyed\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\ASyed\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "663/663 [==============================] - ETA: 0s - loss: 1.8976 - categorical_accuracy: 0.3952Source path =  G:\\My Drive\\Personal\\upGrad\\MS\\Recurrent Neural Networks\\Project_data\\val ; batch size = 1\n",
            "\n",
            "Epoch 1: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00001-1.89764-0.39517-2.16167-0.49000.h5\n",
            "663/663 [==============================] - 254s 376ms/step - loss: 1.8976 - categorical_accuracy: 0.3952 - val_loss: 2.1617 - val_categorical_accuracy: 0.4900 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "  1/663 [..............................] - ETA: 12s - loss: 1.2494 - categorical_accuracy: 0.0000e+00"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ASyed\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "663/663 [==============================] - ETA: 0s - loss: 1.0559 - categorical_accuracy: 0.5958\n",
            "Epoch 2: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00002-1.05591-0.59578-1.08228-0.67000.h5\n",
            "663/663 [==============================] - 197s 297ms/step - loss: 1.0559 - categorical_accuracy: 0.5958 - val_loss: 1.0823 - val_categorical_accuracy: 0.6700 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 0.6762 - categorical_accuracy: 0.7602\n",
            "Epoch 3: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00003-0.67621-0.76018-0.92267-0.74000.h5\n",
            "663/663 [==============================] - 193s 292ms/step - loss: 0.6762 - categorical_accuracy: 0.7602 - val_loss: 0.9227 - val_categorical_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 0.4351 - categorical_accuracy: 0.8296\n",
            "Epoch 4: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00004-0.43515-0.82956-1.05031-0.67000.h5\n",
            "663/663 [==============================] - 186s 281ms/step - loss: 0.4351 - categorical_accuracy: 0.8296 - val_loss: 1.0503 - val_categorical_accuracy: 0.6700 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 0.3042 - categorical_accuracy: 0.8793\n",
            "Epoch 5: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00005-0.30422-0.87934-1.45448-0.68000.h5\n",
            "663/663 [==============================] - 179s 271ms/step - loss: 0.3042 - categorical_accuracy: 0.8793 - val_loss: 1.4545 - val_categorical_accuracy: 0.6800 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 0.2972 - categorical_accuracy: 0.8914\n",
            "Epoch 6: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00006-0.29718-0.89140-1.77237-0.65000.h5\n",
            "663/663 [==============================] - 177s 268ms/step - loss: 0.2972 - categorical_accuracy: 0.8914 - val_loss: 1.7724 - val_categorical_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 0.2699 - categorical_accuracy: 0.9186\n",
            "Epoch 7: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00007-0.26995-0.91855-0.92186-0.79000.h5\n",
            "663/663 [==============================] - 173s 261ms/step - loss: 0.2699 - categorical_accuracy: 0.9186 - val_loss: 0.9219 - val_categorical_accuracy: 0.7900 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 0.1083 - categorical_accuracy: 0.9623\n",
            "Epoch 8: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00008-0.10829-0.96229-1.34807-0.76000.h5\n",
            "663/663 [==============================] - 161s 243ms/step - loss: 0.1083 - categorical_accuracy: 0.9623 - val_loss: 1.3481 - val_categorical_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 0.1660 - categorical_accuracy: 0.9563\n",
            "Epoch 9: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00009-0.16597-0.95626-2.78983-0.65000.h5\n",
            "663/663 [==============================] - 195s 295ms/step - loss: 0.1660 - categorical_accuracy: 0.9563 - val_loss: 2.7898 - val_categorical_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 0.2557 - categorical_accuracy: 0.9065\n",
            "Epoch 10: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00010-0.25571-0.90649-0.91785-0.82000.h5\n",
            "663/663 [==============================] - 186s 281ms/step - loss: 0.2557 - categorical_accuracy: 0.9065 - val_loss: 0.9179 - val_categorical_accuracy: 0.8200 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 0.0689 - categorical_accuracy: 0.9759\n",
            "Epoch 11: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00011-0.06892-0.97587-1.79006-0.75000.h5\n",
            "663/663 [==============================] - 168s 254ms/step - loss: 0.0689 - categorical_accuracy: 0.9759 - val_loss: 1.7901 - val_categorical_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 0.1075 - categorical_accuracy: 0.9578\n",
            "Epoch 12: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00012-0.10747-0.95777-1.31524-0.81000.h5\n",
            "663/663 [==============================] - 153s 232ms/step - loss: 0.1075 - categorical_accuracy: 0.9578 - val_loss: 1.3152 - val_categorical_accuracy: 0.8100 - lr: 0.0010\n",
            "Epoch 13/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 0.0290 - categorical_accuracy: 0.9894\n",
            "Epoch 13: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00013-0.02900-0.98944-1.34345-0.82000.h5\n",
            "663/663 [==============================] - 160s 241ms/step - loss: 0.0290 - categorical_accuracy: 0.9894 - val_loss: 1.3434 - val_categorical_accuracy: 0.8200 - lr: 0.0010\n",
            "Epoch 14/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 0.0119 - categorical_accuracy: 0.9970\n",
            "Epoch 14: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00014-0.01188-0.99698-1.49615-0.83000.h5\n",
            "663/663 [==============================] - 183s 276ms/step - loss: 0.0119 - categorical_accuracy: 0.9970 - val_loss: 1.4962 - val_categorical_accuracy: 0.8300 - lr: 0.0010\n",
            "Epoch 15/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 0.0020 - categorical_accuracy: 1.0000\n",
            "Epoch 15: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00015-0.00201-1.00000-1.21714-0.86000.h5\n",
            "663/663 [==============================] - 198s 299ms/step - loss: 0.0020 - categorical_accuracy: 1.0000 - val_loss: 1.2171 - val_categorical_accuracy: 0.8600 - lr: 0.0010\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x25a419f1e90>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_generator = generator(train_path, train_doc, batch_size, img_idx, image_height, image_width)\n",
        "val_generator = generator(val_path, val_doc, batch_size, img_idx, image_height, image_width)\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "\n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "\n",
        "filepath = model_path_prefix + model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=5, min_lr=0.001) # write the REducelronplateau code here\n",
        "callbacks_list = [checkpoint, LR]\n",
        "\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1\n",
        "    \n",
        "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n",
        "                    callbacks=callbacks_list, validation_data=val_generator,\n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <font color='blue'>2.1.3 Accuracy & Remarks</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>Accuracy</b>:\n",
        "- Training: 1.0\n",
        "- Validation: 0.86\n",
        "\n",
        "<b>Remarks:</b>\n",
        "- Started with batch size 1 to check the model is working \n",
        "- Validation accuracy is not bad\n",
        "- High difference between Training vs Validation, shows model to be overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <font color='blue'>2.1.4 Next Actions</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Increase Batch Size\n",
        "- Increase Image Height and Width\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <font color='blue'>2.2 Model 2 - </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <font color='blue'>2.2.1 Design, Compile & Summary</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d_6 (Conv3D)           (None, 10, 100, 100, 16   1312      \n",
            "                             )                                   \n",
            "                                                                 \n",
            " max_pooling3d_6 (MaxPoolin  (None, 5, 50, 50, 16)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 5, 50, 50, 16)     64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_7 (Conv3D)           (None, 5, 50, 50, 32)     13856     \n",
            "                                                                 \n",
            " max_pooling3d_7 (MaxPoolin  (None, 2, 25, 25, 32)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 2, 25, 25, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_8 (Conv3D)           (None, 2, 25, 25, 64)     55360     \n",
            "                                                                 \n",
            " max_pooling3d_8 (MaxPoolin  (None, 1, 12, 12, 64)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_8 (Bat  (None, 1, 12, 12, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 9216)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               1179776   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1251397 (4.77 MB)\n",
            "Trainable params: 1251173 (4.77 MB)\n",
            "Non-trainable params: 224 (896.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "img_idx = list(range(1,30,3))\n",
        "frames = len(img_idx)\n",
        "image_height = 100\n",
        "image_width = 100\n",
        "batch_size = 32\n",
        "num_classes = 5\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv3D(16, (3,3,3), padding='same', input_shape=(frames, image_height, image_width, 3), activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(32, (3,3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(64, (3,3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "optimiser = \"adam\"\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <font color='blue'>2.2.2 Model Training</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHHcxwpjfSm6",
        "outputId": "88b3de61-0b84-47f1-9d1e-a9030a4b0ac6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Source path =  G:\\My Drive\\Personal\\upGrad\\MS\\Recurrent Neural Networks\\Project_data\\train ; batch size = 32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ASyed\\AppData\\Local\\Temp\\ipykernel_46732\\842919994.py:26: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.4074 - categorical_accuracy: 0.5521Source path =  G:\\My Drive\\Personal\\upGrad\\MS\\Recurrent Neural Networks\\Project_data\\val ; batch size = 32\n",
            "\n",
            "Epoch 1: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00001-1.40741-0.55208-31.82745-0.27344.h5\n",
            "21/21 [==============================] - 158s 8s/step - loss: 1.4074 - categorical_accuracy: 0.5521 - val_loss: 31.8275 - val_categorical_accuracy: 0.2734 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.5045 - categorical_accuracy: 0.8259\n",
            "Epoch 2: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00002-0.50449-0.82589-22.73162-0.36719.h5\n",
            "21/21 [==============================] - 160s 8s/step - loss: 0.5045 - categorical_accuracy: 0.8259 - val_loss: 22.7316 - val_categorical_accuracy: 0.3672 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.1814 - categorical_accuracy: 0.9390\n",
            "Epoch 3: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00003-0.18143-0.93899-14.05996-0.41406.h5\n",
            "21/21 [==============================] - 136s 7s/step - loss: 0.1814 - categorical_accuracy: 0.9390 - val_loss: 14.0600 - val_categorical_accuracy: 0.4141 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0534 - categorical_accuracy: 0.9866\n",
            "Epoch 4: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00004-0.05341-0.98661-9.70952-0.47656.h5\n",
            "21/21 [==============================] - 154s 8s/step - loss: 0.0534 - categorical_accuracy: 0.9866 - val_loss: 9.7095 - val_categorical_accuracy: 0.4766 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0318 - categorical_accuracy: 0.9851\n",
            "Epoch 5: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00005-0.03178-0.98512-9.80005-0.43750.h5\n",
            "21/21 [==============================] - 149s 7s/step - loss: 0.0318 - categorical_accuracy: 0.9851 - val_loss: 9.8000 - val_categorical_accuracy: 0.4375 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0132 - categorical_accuracy: 0.9970\n",
            "Epoch 6: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00006-0.01317-0.99702-2.93209-0.57812.h5\n",
            "21/21 [==============================] - 161s 8s/step - loss: 0.0132 - categorical_accuracy: 0.9970 - val_loss: 2.9321 - val_categorical_accuracy: 0.5781 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0115 - categorical_accuracy: 0.9970\n",
            "Epoch 7: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00007-0.01153-0.99702-2.86880-0.50000.h5\n",
            "21/21 [==============================] - 157s 8s/step - loss: 0.0115 - categorical_accuracy: 0.9970 - val_loss: 2.8688 - val_categorical_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0037 - categorical_accuracy: 1.0000\n",
            "Epoch 8: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00008-0.00368-1.00000-1.53002-0.67188.h5\n",
            "21/21 [==============================] - 156s 8s/step - loss: 0.0037 - categorical_accuracy: 1.0000 - val_loss: 1.5300 - val_categorical_accuracy: 0.6719 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0014 - categorical_accuracy: 1.0000\n",
            "Epoch 9: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00009-0.00137-1.00000-0.98312-0.71875.h5\n",
            "21/21 [==============================] - 160s 8s/step - loss: 0.0014 - categorical_accuracy: 1.0000 - val_loss: 0.9831 - val_categorical_accuracy: 0.7188 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 9.2551e-04 - categorical_accuracy: 1.0000\n",
            "Epoch 10: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00010-0.00093-1.00000-0.82821-0.74219.h5\n",
            "21/21 [==============================] - 158s 8s/step - loss: 9.2551e-04 - categorical_accuracy: 1.0000 - val_loss: 0.8282 - val_categorical_accuracy: 0.7422 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 7.2535e-04 - categorical_accuracy: 1.0000\n",
            "Epoch 11: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00011-0.00073-1.00000-0.76834-0.79688.h5\n",
            "21/21 [==============================] - 159s 8s/step - loss: 7.2535e-04 - categorical_accuracy: 1.0000 - val_loss: 0.7683 - val_categorical_accuracy: 0.7969 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 6.4044e-04 - categorical_accuracy: 1.0000\n",
            "Epoch 12: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00012-0.00064-1.00000-0.58292-0.81250.h5\n",
            "21/21 [==============================] - 169s 8s/step - loss: 6.4044e-04 - categorical_accuracy: 1.0000 - val_loss: 0.5829 - val_categorical_accuracy: 0.8125 - lr: 0.0010\n",
            "Epoch 13/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 5.2698e-04 - categorical_accuracy: 1.0000\n",
            "Epoch 13: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00013-0.00053-1.00000-0.53228-0.85938.h5\n",
            "21/21 [==============================] - 158s 8s/step - loss: 5.2698e-04 - categorical_accuracy: 1.0000 - val_loss: 0.5323 - val_categorical_accuracy: 0.8594 - lr: 0.0010\n",
            "Epoch 14/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 4.6037e-04 - categorical_accuracy: 1.0000\n",
            "Epoch 14: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00014-0.00046-1.00000-0.55291-0.85938.h5\n",
            "21/21 [==============================] - 160s 8s/step - loss: 4.6037e-04 - categorical_accuracy: 1.0000 - val_loss: 0.5529 - val_categorical_accuracy: 0.8594 - lr: 0.0010\n",
            "Epoch 15/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 3.7158e-04 - categorical_accuracy: 1.0000\n",
            "Epoch 15: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00015-0.00037-1.00000-0.42249-0.89844.h5\n",
            "21/21 [==============================] - 157s 8s/step - loss: 3.7158e-04 - categorical_accuracy: 1.0000 - val_loss: 0.4225 - val_categorical_accuracy: 0.8984 - lr: 0.0010\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x25a23342590>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_generator = generator(train_path, train_doc, batch_size, img_idx, image_height, image_width)\n",
        "val_generator = generator(val_path, val_doc, batch_size, img_idx, image_height, image_width)\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "\n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "\n",
        "filepath = model_path_prefix + model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=5, min_lr=0.001) # write the REducelronplateau code here\n",
        "callbacks_list = [checkpoint, LR]\n",
        "\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1\n",
        "\n",
        "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n",
        "                    callbacks=callbacks_list, validation_data=val_generator,\n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <font color='blue'>2.2.3 Accuracy & Remarks</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>Accuracy</b>:\n",
        "- Training: 1.0\n",
        "- Validation: 0.89\n",
        "\n",
        "<b>Remarks:</b>\n",
        "- Increased batch size + Image size, might have degraded performance\n",
        "- Validation Accuracy has increased\n",
        "- Training accuracy at 100% and High difference between Training vs Validation, shows model to be overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <font color='blue'>2.2.4 Next Actions</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Introduced Dropout with 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <font color='blue'>2.3 Model 3 - </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS2rAehy2NJO"
      },
      "source": [
        "#### <font color='blue'>2.3.1 Design, Compile & Summary</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d_9 (Conv3D)           (None, 10, 100, 100, 16   1312      \n",
            "                             )                                   \n",
            "                                                                 \n",
            " max_pooling3d_9 (MaxPoolin  (None, 5, 50, 50, 16)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 5, 50, 50, 16)     0         \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, 5, 50, 50, 16)     64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_10 (Conv3D)          (None, 5, 50, 50, 32)     13856     \n",
            "                                                                 \n",
            " max_pooling3d_10 (MaxPooli  (None, 2, 25, 25, 32)     0         \n",
            " ng3D)                                                           \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 2, 25, 25, 32)     0         \n",
            "                                                                 \n",
            " batch_normalization_10 (Ba  (None, 2, 25, 25, 32)     128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv3d_11 (Conv3D)          (None, 2, 25, 25, 64)     55360     \n",
            "                                                                 \n",
            " max_pooling3d_11 (MaxPooli  (None, 1, 12, 12, 64)     0         \n",
            " ng3D)                                                           \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1, 12, 12, 64)     0         \n",
            "                                                                 \n",
            " batch_normalization_11 (Ba  (None, 1, 12, 12, 64)     256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 9216)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               1179776   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1251397 (4.77 MB)\n",
            "Trainable params: 1251173 (4.77 MB)\n",
            "Non-trainable params: 224 (896.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "img_idx = list(range(1,30,3))\n",
        "frames = len(img_idx)\n",
        "image_height = 100\n",
        "image_width = 100\n",
        "batch_size = 32\n",
        "num_classes = 5\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv3D(16, (3,3,3), padding='same', input_shape=(frames, image_height, image_width, 3), activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(32, (3,3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(64, (3,3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "optimiser = \"adam\"\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <font color='blue'>2.3.2 Model Training</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmR_XI-9nnaH",
        "outputId": "508807b0-b9e8-40fb-d59b-b4f9ad0f02a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Source path =  G:\\My Drive\\Personal\\upGrad\\MS\\Recurrent Neural Networks\\Project_data\\train ; batch size = 32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ASyed\\AppData\\Local\\Temp\\ipykernel_46732\\842919994.py:26: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 2.0307 - categorical_accuracy: 0.3423Source path =  G:\\My Drive\\Personal\\upGrad\\MS\\Recurrent Neural Networks\\Project_data\\val ; batch size = 32\n",
            "\n",
            "Epoch 1: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00001-2.03073-0.34226-8.60648-0.29688.h5\n",
            "21/21 [==============================] - 193s 9s/step - loss: 2.0307 - categorical_accuracy: 0.3423 - val_loss: 8.6065 - val_categorical_accuracy: 0.2969 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.4042 - categorical_accuracy: 0.4554\n",
            "Epoch 2: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00002-1.40424-0.45536-4.19344-0.27344.h5\n",
            "21/21 [==============================] - 186s 9s/step - loss: 1.4042 - categorical_accuracy: 0.4554 - val_loss: 4.1934 - val_categorical_accuracy: 0.2734 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.1220 - categorical_accuracy: 0.5580\n",
            "Epoch 3: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00003-1.12200-0.55804-2.34492-0.33594.h5\n",
            "21/21 [==============================] - 177s 9s/step - loss: 1.1220 - categorical_accuracy: 0.5580 - val_loss: 2.3449 - val_categorical_accuracy: 0.3359 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.9201 - categorical_accuracy: 0.6518\n",
            "Epoch 4: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00004-0.92009-0.65179-0.94233-0.67188.h5\n",
            "21/21 [==============================] - 157s 8s/step - loss: 0.9201 - categorical_accuracy: 0.6518 - val_loss: 0.9423 - val_categorical_accuracy: 0.6719 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.8896 - categorical_accuracy: 0.6503\n",
            "Epoch 5: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00005-0.88956-0.65030-0.73387-0.77344.h5\n",
            "21/21 [==============================] - 115s 6s/step - loss: 0.8896 - categorical_accuracy: 0.6503 - val_loss: 0.7339 - val_categorical_accuracy: 0.7734 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.7169 - categorical_accuracy: 0.7083\n",
            "Epoch 6: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00006-0.71692-0.70833-0.85306-0.67188.h5\n",
            "21/21 [==============================] - 140s 7s/step - loss: 0.7169 - categorical_accuracy: 0.7083 - val_loss: 0.8531 - val_categorical_accuracy: 0.6719 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.6966 - categorical_accuracy: 0.7307\n",
            "Epoch 7: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00007-0.69655-0.73065-1.03244-0.65625.h5\n",
            "21/21 [==============================] - 133s 7s/step - loss: 0.6966 - categorical_accuracy: 0.7307 - val_loss: 1.0324 - val_categorical_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.5491 - categorical_accuracy: 0.7574\n",
            "Epoch 8: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00008-0.54915-0.75744-1.50521-0.52344.h5\n",
            "21/21 [==============================] - 135s 7s/step - loss: 0.5491 - categorical_accuracy: 0.7574 - val_loss: 1.5052 - val_categorical_accuracy: 0.5234 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.5340 - categorical_accuracy: 0.7842\n",
            "Epoch 9: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00009-0.53398-0.78423-1.62996-0.55469.h5\n",
            "21/21 [==============================] - 131s 7s/step - loss: 0.5340 - categorical_accuracy: 0.7842 - val_loss: 1.6300 - val_categorical_accuracy: 0.5547 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.4039 - categorical_accuracy: 0.8467\n",
            "Epoch 10: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00010-0.40394-0.84673-2.35831-0.45312.h5\n",
            "21/21 [==============================] - 123s 6s/step - loss: 0.4039 - categorical_accuracy: 0.8467 - val_loss: 2.3583 - val_categorical_accuracy: 0.4531 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.4152 - categorical_accuracy: 0.8452\n",
            "Epoch 11: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00011-0.41519-0.84524-1.83719-0.57031.h5\n",
            "21/21 [==============================] - 121s 6s/step - loss: 0.4152 - categorical_accuracy: 0.8452 - val_loss: 1.8372 - val_categorical_accuracy: 0.5703 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.3710 - categorical_accuracy: 0.8676\n",
            "Epoch 12: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00012-0.37101-0.86756-2.30844-0.50781.h5\n",
            "21/21 [==============================] - 125s 6s/step - loss: 0.3710 - categorical_accuracy: 0.8676 - val_loss: 2.3084 - val_categorical_accuracy: 0.5078 - lr: 0.0010\n",
            "Epoch 13/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.3533 - categorical_accuracy: 0.8720\n",
            "Epoch 13: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00013-0.35331-0.87202-2.59030-0.46094.h5\n",
            "21/21 [==============================] - 137s 7s/step - loss: 0.3533 - categorical_accuracy: 0.8720 - val_loss: 2.5903 - val_categorical_accuracy: 0.4609 - lr: 0.0010\n",
            "Epoch 14/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.3023 - categorical_accuracy: 0.8839\n",
            "Epoch 14: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00014-0.30230-0.88393-2.21334-0.53906.h5\n",
            "21/21 [==============================] - 134s 7s/step - loss: 0.3023 - categorical_accuracy: 0.8839 - val_loss: 2.2133 - val_categorical_accuracy: 0.5391 - lr: 0.0010\n",
            "Epoch 15/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.3401 - categorical_accuracy: 0.8705\n",
            "Epoch 15: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00015-0.34010-0.87054-1.72982-0.55469.h5\n",
            "21/21 [==============================] - 137s 7s/step - loss: 0.3401 - categorical_accuracy: 0.8705 - val_loss: 1.7298 - val_categorical_accuracy: 0.5547 - lr: 0.0010\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x25a27e2e1d0>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_generator = generator(train_path, train_doc, batch_size, img_idx, image_height, image_width)\n",
        "val_generator = generator(val_path, val_doc, batch_size, img_idx, image_height, image_width)\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "\n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "\n",
        "filepath = model_path_prefix + model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=5, min_lr=0.001) # write the REducelronplateau code here\n",
        "callbacks_list = [checkpoint, LR]\n",
        "\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1\n",
        "\n",
        "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n",
        "                    callbacks=callbacks_list, validation_data=val_generator,\n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <font color='blue'>2.3.3 Accuracy & Remarks</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>Accuracy</b>:\n",
        "- Training: 0.65\n",
        "- Validation: 0.77\n",
        "\n",
        "<b>Remarks:</b>\n",
        "- Suffered in both Training and Validation Accuracy\n",
        "- Training accuracy is more than Validation, issue in the learning itself"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <font color='blue'>2.3.4 Next Actions</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lakRzPt0NA8l"
      },
      "source": [
        "Change architecture starting with 32 layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <font color='blue'>2.4 Model 4 - </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <font color='blue'>2.4.1 Design, Compile & Summary</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d_15 (Conv3D)          (None, 10, 100, 100, 32   2624      \n",
            "                             )                                   \n",
            "                                                                 \n",
            " max_pooling3d_15 (MaxPooli  (None, 5, 50, 50, 32)     0         \n",
            " ng3D)                                                           \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 5, 50, 50, 32)     0         \n",
            "                                                                 \n",
            " batch_normalization_15 (Ba  (None, 5, 50, 50, 32)     128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv3d_16 (Conv3D)          (None, 5, 50, 50, 64)     55360     \n",
            "                                                                 \n",
            " max_pooling3d_16 (MaxPooli  (None, 2, 25, 25, 64)     0         \n",
            " ng3D)                                                           \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 2, 25, 25, 64)     0         \n",
            "                                                                 \n",
            " batch_normalization_16 (Ba  (None, 2, 25, 25, 64)     256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv3d_17 (Conv3D)          (None, 2, 25, 25, 128)    221312    \n",
            "                                                                 \n",
            " max_pooling3d_17 (MaxPooli  (None, 1, 12, 12, 128)    0         \n",
            " ng3D)                                                           \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 1, 12, 12, 128)    0         \n",
            "                                                                 \n",
            " batch_normalization_17 (Ba  (None, 1, 12, 12, 128)    512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 18432)             0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 256)               4718848   \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5000325 (19.07 MB)\n",
            "Trainable params: 4999877 (19.07 MB)\n",
            "Non-trainable params: 448 (1.75 KB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "img_idx = list(range(1,30,3))\n",
        "frames = len(img_idx)\n",
        "image_height = 100\n",
        "image_width = 100\n",
        "batch_size = 64\n",
        "num_classes = 5\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv3D(32, (3,3,3), padding='same', input_shape=(frames, image_height, image_width, 3), activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(64, (3,3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(128, (3,3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "optimiser = \"adam\"\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <font color='blue'>2.4.2 Model Training</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ-gaR6o69-8",
        "outputId": "c8edc076-ebb3-40fa-9023-188bf59e85f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Source path =  G:\\My Drive\\Personal\\upGrad\\MS\\Recurrent Neural Networks\\Project_data\\train ; batch size = 64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ASyed\\AppData\\Local\\Temp\\ipykernel_46732\\3720141927.py:26: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.1899 - categorical_accuracy: 0.3466 Source path =  G:\\My Drive\\Personal\\upGrad\\MS\\Recurrent Neural Networks\\Project_data\\val ; batch size = 64\n",
            "\n",
            "Epoch 1: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00001-2.18986-0.34659-40.54904-0.26562.h5\n",
            "11/11 [==============================] - 301s 30s/step - loss: 2.1899 - categorical_accuracy: 0.3466 - val_loss: 40.5490 - val_categorical_accuracy: 0.2656 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4236 - categorical_accuracy: 0.4986 \n",
            "Epoch 2: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00002-1.42362-0.49858-40.92770-0.23438.h5\n",
            "11/11 [==============================] - 336s 33s/step - loss: 1.4236 - categorical_accuracy: 0.4986 - val_loss: 40.9277 - val_categorical_accuracy: 0.2344 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0030 - categorical_accuracy: 0.6207 \n",
            "Epoch 3: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00003-1.00302-0.62074-27.05127-0.23438.h5\n",
            "11/11 [==============================] - 301s 30s/step - loss: 1.0030 - categorical_accuracy: 0.6207 - val_loss: 27.0513 - val_categorical_accuracy: 0.2344 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.8836 - categorical_accuracy: 0.6719 \n",
            "Epoch 4: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00004-0.88359-0.67188-25.91345-0.21875.h5\n",
            "11/11 [==============================] - 318s 31s/step - loss: 0.8836 - categorical_accuracy: 0.6719 - val_loss: 25.9134 - val_categorical_accuracy: 0.2188 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.7434 - categorical_accuracy: 0.7003 \n",
            "Epoch 5: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00005-0.74337-0.70028-15.99927-0.31250.h5\n",
            "11/11 [==============================] - 367s 36s/step - loss: 0.7434 - categorical_accuracy: 0.7003 - val_loss: 15.9993 - val_categorical_accuracy: 0.3125 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.6194 - categorical_accuracy: 0.7585 \n",
            "Epoch 6: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00006-0.61941-0.75852-5.38813-0.34375.h5\n",
            "11/11 [==============================] - 520s 51s/step - loss: 0.6194 - categorical_accuracy: 0.7585 - val_loss: 5.3881 - val_categorical_accuracy: 0.3438 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.5345 - categorical_accuracy: 0.8011 \n",
            "Epoch 7: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00007-0.53449-0.80114-3.67095-0.45312.h5\n",
            "11/11 [==============================] - 729s 72s/step - loss: 0.5345 - categorical_accuracy: 0.8011 - val_loss: 3.6709 - val_categorical_accuracy: 0.4531 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4653 - categorical_accuracy: 0.8253 \n",
            "Epoch 8: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00008-0.46529-0.82528-2.50583-0.50000.h5\n",
            "11/11 [==============================] - 598s 59s/step - loss: 0.4653 - categorical_accuracy: 0.8253 - val_loss: 2.5058 - val_categorical_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4556 - categorical_accuracy: 0.8253 \n",
            "Epoch 9: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00009-0.45561-0.82528-2.86569-0.48438.h5\n",
            "11/11 [==============================] - 435s 43s/step - loss: 0.4556 - categorical_accuracy: 0.8253 - val_loss: 2.8657 - val_categorical_accuracy: 0.4844 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3615 - categorical_accuracy: 0.8651 \n",
            "Epoch 10: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00010-0.36152-0.86506-0.84944-0.75781.h5\n",
            "11/11 [==============================] - 605s 60s/step - loss: 0.3615 - categorical_accuracy: 0.8651 - val_loss: 0.8494 - val_categorical_accuracy: 0.7578 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2467 - categorical_accuracy: 0.9091 \n",
            "Epoch 11: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00011-0.24671-0.90909-0.75231-0.81250.h5\n",
            "11/11 [==============================] - 611s 60s/step - loss: 0.2467 - categorical_accuracy: 0.9091 - val_loss: 0.7523 - val_categorical_accuracy: 0.8125 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2725 - categorical_accuracy: 0.8935 \n",
            "Epoch 12: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00012-0.27254-0.89347-0.77396-0.82031.h5\n",
            "11/11 [==============================] - 323s 32s/step - loss: 0.2725 - categorical_accuracy: 0.8935 - val_loss: 0.7740 - val_categorical_accuracy: 0.8203 - lr: 0.0010\n",
            "Epoch 13/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1965 - categorical_accuracy: 0.9233 \n",
            "Epoch 13: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00013-0.19651-0.92330-1.07000-0.76562.h5\n",
            "11/11 [==============================] - 309s 30s/step - loss: 0.1965 - categorical_accuracy: 0.9233 - val_loss: 1.0700 - val_categorical_accuracy: 0.7656 - lr: 0.0010\n",
            "Epoch 14/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1757 - categorical_accuracy: 0.9332 \n",
            "Epoch 14: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00014-0.17568-0.93324-1.18008-0.70312.h5\n",
            "11/11 [==============================] - 302s 30s/step - loss: 0.1757 - categorical_accuracy: 0.9332 - val_loss: 1.1801 - val_categorical_accuracy: 0.7031 - lr: 0.0010\n",
            "Epoch 15/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1721 - categorical_accuracy: 0.9418 \n",
            "Epoch 15: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00015-0.17209-0.94176-1.18958-0.70312.h5\n",
            "11/11 [==============================] - 301s 30s/step - loss: 0.1721 - categorical_accuracy: 0.9418 - val_loss: 1.1896 - val_categorical_accuracy: 0.7031 - lr: 5.0000e-04\n"
          ]
        }
      ],
      "source": [
        "train_generator = generator(train_path, train_doc, batch_size, img_idx, image_height, image_width)\n",
        "val_generator = generator(val_path, val_doc, batch_size, img_idx, image_height, image_width)\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "\n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "\n",
        "filepath = model_path_prefix + model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-5) # write the REducelronplateau code here\n",
        "callbacks_list = [checkpoint, LR]\n",
        "\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1\n",
        "\n",
        "history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n",
        "                    callbacks=callbacks_list, validation_data=val_generator,\n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <font color='blue'>2.4.3 Accuracy & Remarks</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>Accuracy</b>:\n",
        "- Training: 0.89\n",
        "- Validation: 0.82\n",
        "\n",
        "<b>Remarks:</b>\n",
        "- Training and Validation Accuracy increased\n",
        "- Validation accuracy is not in acceptable range\n",
        "- High number of trainable params increasing the model size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <font color='blue'>2.4.4 Next Actions</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE-H3yuTg8hy"
      },
      "source": [
        "- Increase batch size to 64\n",
        "- Crop image to 50 x 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <font color='blue'>2.5 Model 5 - </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <font color='blue'>2.5.1 Design, Compile & Summary</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d_18 (Conv3D)          (None, 10, 50, 50, 32)    2624      \n",
            "                                                                 \n",
            " max_pooling3d_18 (MaxPooli  (None, 5, 25, 25, 32)     0         \n",
            " ng3D)                                                           \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 5, 25, 25, 32)     0         \n",
            "                                                                 \n",
            " batch_normalization_18 (Ba  (None, 5, 25, 25, 32)     128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv3d_19 (Conv3D)          (None, 5, 25, 25, 64)     55360     \n",
            "                                                                 \n",
            " max_pooling3d_19 (MaxPooli  (None, 2, 12, 12, 64)     0         \n",
            " ng3D)                                                           \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 2, 12, 12, 64)     0         \n",
            "                                                                 \n",
            " batch_normalization_19 (Ba  (None, 2, 12, 12, 64)     256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv3d_20 (Conv3D)          (None, 2, 12, 12, 128)    221312    \n",
            "                                                                 \n",
            " max_pooling3d_20 (MaxPooli  (None, 1, 6, 6, 128)      0         \n",
            " ng3D)                                                           \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 1, 6, 6, 128)      0         \n",
            "                                                                 \n",
            " batch_normalization_20 (Ba  (None, 1, 6, 6, 128)      512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 256)               1179904   \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1461381 (5.57 MB)\n",
            "Trainable params: 1460933 (5.57 MB)\n",
            "Non-trainable params: 448 (1.75 KB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "img_idx = list(range(1,30,3))\n",
        "frames = len(img_idx)\n",
        "image_height = 50\n",
        "image_width = 50\n",
        "batch_size = 64\n",
        "num_classes = 5\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv3D(32, (3,3,3), padding='same', input_shape=(frames, image_height, image_width, 3), activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(64, (3,3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(128, (3,3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "optimiser = \"adam\"\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <font color='blue'>2.5.2 Model Training</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yjNjRE0Tg5hx",
        "outputId": "073e367e-a352-4326-b5fb-3a3864be1341"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Source path =  G:\\My Drive\\Personal\\upGrad\\MS\\Recurrent Neural Networks\\Project_data\\train ; batch size = 64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ASyed\\AppData\\Local\\Temp\\ipykernel_46732\\3720141927.py:26: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.2656 - categorical_accuracy: 0.3139 Source path =  G:\\My Drive\\Personal\\upGrad\\MS\\Recurrent Neural Networks\\Project_data\\val ; batch size = 64\n",
            "\n",
            "Epoch 1: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00001-2.26564-0.31392-20.95386-0.20312.h5\n",
            "11/11 [==============================] - 298s 29s/step - loss: 2.2656 - categorical_accuracy: 0.3139 - val_loss: 20.9539 - val_categorical_accuracy: 0.2031 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6287 - categorical_accuracy: 0.4119 \n",
            "Epoch 2: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00002-1.62866-0.41193-16.19118-0.24219.h5\n",
            "11/11 [==============================] - 251s 25s/step - loss: 1.6287 - categorical_accuracy: 0.4119 - val_loss: 16.1912 - val_categorical_accuracy: 0.2422 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4189 - categorical_accuracy: 0.5057 \n",
            "Epoch 3: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00003-1.41891-0.50568-13.20505-0.17188.h5\n",
            "11/11 [==============================] - 193s 19s/step - loss: 1.4189 - categorical_accuracy: 0.5057 - val_loss: 13.2051 - val_categorical_accuracy: 0.1719 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2566 - categorical_accuracy: 0.5241 \n",
            "Epoch 4: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00004-1.25662-0.52415-9.33715-0.22656.h5\n",
            "11/11 [==============================] - 202s 20s/step - loss: 1.2566 - categorical_accuracy: 0.5241 - val_loss: 9.3372 - val_categorical_accuracy: 0.2266 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1263 - categorical_accuracy: 0.5526 \n",
            "Epoch 5: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00005-1.12633-0.55256-10.12846-0.20312.h5\n",
            "11/11 [==============================] - 234s 23s/step - loss: 1.1263 - categorical_accuracy: 0.5526 - val_loss: 10.1285 - val_categorical_accuracy: 0.2031 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.9559 - categorical_accuracy: 0.6236 \n",
            "Epoch 6: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00006-0.95590-0.62358-5.23939-0.21875.h5\n",
            "11/11 [==============================] - 238s 24s/step - loss: 0.9559 - categorical_accuracy: 0.6236 - val_loss: 5.2394 - val_categorical_accuracy: 0.2188 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.8897 - categorical_accuracy: 0.6250 \n",
            "Epoch 7: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00007-0.88968-0.62500-3.10506-0.28125.h5\n",
            "11/11 [==============================] - 252s 25s/step - loss: 0.8897 - categorical_accuracy: 0.6250 - val_loss: 3.1051 - val_categorical_accuracy: 0.2812 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.7663 - categorical_accuracy: 0.6761 \n",
            "Epoch 8: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00008-0.76626-0.67614-2.16280-0.41406.h5\n",
            "11/11 [==============================] - 229s 23s/step - loss: 0.7663 - categorical_accuracy: 0.6761 - val_loss: 2.1628 - val_categorical_accuracy: 0.4141 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.7442 - categorical_accuracy: 0.7088 \n",
            "Epoch 9: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00009-0.74422-0.70881-1.17286-0.60938.h5\n",
            "11/11 [==============================] - 241s 24s/step - loss: 0.7442 - categorical_accuracy: 0.7088 - val_loss: 1.1729 - val_categorical_accuracy: 0.6094 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.6725 - categorical_accuracy: 0.7514 \n",
            "Epoch 10: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00010-0.67251-0.75142-0.80832-0.71094.h5\n",
            "11/11 [==============================] - 225s 22s/step - loss: 0.6725 - categorical_accuracy: 0.7514 - val_loss: 0.8083 - val_categorical_accuracy: 0.7109 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.5936 - categorical_accuracy: 0.7713 \n",
            "Epoch 11: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00011-0.59356-0.77131-0.76107-0.79688.h5\n",
            "11/11 [==============================] - 208s 21s/step - loss: 0.5936 - categorical_accuracy: 0.7713 - val_loss: 0.7611 - val_categorical_accuracy: 0.7969 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.5393 - categorical_accuracy: 0.7969 \n",
            "Epoch 12: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00012-0.53926-0.79688-0.60273-0.79688.h5\n",
            "11/11 [==============================] - 236s 23s/step - loss: 0.5393 - categorical_accuracy: 0.7969 - val_loss: 0.6027 - val_categorical_accuracy: 0.7969 - lr: 0.0010\n",
            "Epoch 13/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.5840 - categorical_accuracy: 0.7656 \n",
            "Epoch 13: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00013-0.58400-0.76562-0.71583-0.75000.h5\n",
            "11/11 [==============================] - 241s 24s/step - loss: 0.5840 - categorical_accuracy: 0.7656 - val_loss: 0.7158 - val_categorical_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 14/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.5241 - categorical_accuracy: 0.8097 \n",
            "Epoch 14: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00014-0.52406-0.80966-0.83018-0.75781.h5\n",
            "11/11 [==============================] - 198s 20s/step - loss: 0.5241 - categorical_accuracy: 0.8097 - val_loss: 0.8302 - val_categorical_accuracy: 0.7578 - lr: 0.0010\n",
            "Epoch 15/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4681 - categorical_accuracy: 0.8224 \n",
            "Epoch 15: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00015-0.46809-0.82244-0.74213-0.75000.h5\n",
            "11/11 [==============================] - 169s 17s/step - loss: 0.4681 - categorical_accuracy: 0.8224 - val_loss: 0.7421 - val_categorical_accuracy: 0.7500 - lr: 0.0010\n"
          ]
        }
      ],
      "source": [
        "train_generator = generator(train_path, train_doc, batch_size, img_idx, image_height, image_width)\n",
        "val_generator = generator(val_path, val_doc, batch_size, img_idx, image_height, image_width)\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "\n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "\n",
        "filepath = model_path_prefix + model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-5) # write the REducelronplateau code here\n",
        "callbacks_list = [checkpoint, LR]\n",
        "\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1\n",
        "\n",
        "history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n",
        "                    callbacks=callbacks_list, validation_data=val_generator,\n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <font color='blue'>2.5.3 Accuracy & Remarks</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>Accuracy</b>:\n",
        "- Training: 0.79\n",
        "- Validation: 0.79\n",
        "\n",
        "<b>Remarks:</b>\n",
        "- Impacted performance a lot\n",
        "- Validation accuracy decreased\n",
        "- Both Training and Valdiation accuracies are in acceptable range and there isnt much difference either"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <font color='blue'>2.5.4 Next Actions</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7GMAyyqknPR"
      },
      "source": [
        "- Reduce batch size to 32\n",
        "- Change architecture to start with 8 layers, to reduce size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <font color='blue'>2.6 Model 6 - </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <font color='blue'>2.6.1 Design, Compile & Summary</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d_21 (Conv3D)          (None, 10, 50, 50, 8)     656       \n",
            "                                                                 \n",
            " max_pooling3d_21 (MaxPooli  (None, 5, 25, 25, 8)      0         \n",
            " ng3D)                                                           \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 5, 25, 25, 8)      0         \n",
            "                                                                 \n",
            " batch_normalization_21 (Ba  (None, 5, 25, 25, 8)      32        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv3d_22 (Conv3D)          (None, 5, 25, 25, 16)     3472      \n",
            "                                                                 \n",
            " max_pooling3d_22 (MaxPooli  (None, 2, 12, 12, 16)     0         \n",
            " ng3D)                                                           \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 2, 12, 12, 16)     0         \n",
            "                                                                 \n",
            " batch_normalization_22 (Ba  (None, 2, 12, 12, 16)     64        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv3d_23 (Conv3D)          (None, 2, 12, 12, 32)     13856     \n",
            "                                                                 \n",
            " max_pooling3d_23 (MaxPooli  (None, 1, 6, 6, 32)       0         \n",
            " ng3D)                                                           \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 1, 6, 6, 32)       0         \n",
            "                                                                 \n",
            " batch_normalization_23 (Ba  (None, 1, 6, 6, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 1152)              0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 64)                73792     \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 92325 (360.64 KB)\n",
            "Trainable params: 92213 (360.21 KB)\n",
            "Non-trainable params: 112 (448.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "img_idx = list(range(1,30,3))\n",
        "frames = len(img_idx)\n",
        "image_height = 50\n",
        "image_width = 50\n",
        "batch_size = 32\n",
        "num_classes = 5\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv3D(8, (3,3,3), padding='same', input_shape=(frames, image_height, image_width, 3), activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(16, (3,3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(32, (3,3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "optimiser = \"adam\"\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <font color='blue'>2.6.2 Model Training</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-SuLH3OykglP",
        "outputId": "d841db2f-80cf-40c0-9dfb-c0b30afcc2fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Source path =  G:\\My Drive\\Personal\\upGrad\\MS\\Recurrent Neural Networks\\Project_data\\train ; batch size = 32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ASyed\\AppData\\Local\\Temp\\ipykernel_46732\\3720141927.py:26: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 2.2661 - categorical_accuracy: 0.2158Source path =  G:\\My Drive\\Personal\\upGrad\\MS\\Recurrent Neural Networks\\Project_data\\val ; batch size = 32\n",
            "\n",
            "Epoch 1: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00001-2.26614-0.21577-3.01016-0.22656.h5\n",
            "21/21 [==============================] - 254s 12s/step - loss: 2.2661 - categorical_accuracy: 0.2158 - val_loss: 3.0102 - val_categorical_accuracy: 0.2266 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.9355 - categorical_accuracy: 0.2455\n",
            "Epoch 2: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00002-1.93554-0.24554-1.87922-0.24219.h5\n",
            "21/21 [==============================] - 242s 12s/step - loss: 1.9355 - categorical_accuracy: 0.2455 - val_loss: 1.8792 - val_categorical_accuracy: 0.2422 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.6014 - categorical_accuracy: 0.3214\n",
            "Epoch 3: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00003-1.60138-0.32143-1.37295-0.35156.h5\n",
            "21/21 [==============================] - 226s 11s/step - loss: 1.6014 - categorical_accuracy: 0.3214 - val_loss: 1.3730 - val_categorical_accuracy: 0.3516 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.4673 - categorical_accuracy: 0.3869\n",
            "Epoch 4: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00004-1.46727-0.38690-1.20447-0.51562.h5\n",
            "21/21 [==============================] - 212s 11s/step - loss: 1.4673 - categorical_accuracy: 0.3869 - val_loss: 1.2045 - val_categorical_accuracy: 0.5156 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.4445 - categorical_accuracy: 0.4033\n",
            "Epoch 5: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00005-1.44452-0.40327-1.19393-0.46875.h5\n",
            "21/21 [==============================] - 210s 10s/step - loss: 1.4445 - categorical_accuracy: 0.4033 - val_loss: 1.1939 - val_categorical_accuracy: 0.4688 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.3131 - categorical_accuracy: 0.4479\n",
            "Epoch 6: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00006-1.31306-0.44792-1.33560-0.37500.h5\n",
            "21/21 [==============================] - 220s 11s/step - loss: 1.3131 - categorical_accuracy: 0.4479 - val_loss: 1.3356 - val_categorical_accuracy: 0.3750 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.2054 - categorical_accuracy: 0.4658\n",
            "Epoch 7: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00007-1.20545-0.46577-1.58139-0.36719.h5\n",
            "21/21 [==============================] - 205s 10s/step - loss: 1.2054 - categorical_accuracy: 0.4658 - val_loss: 1.5814 - val_categorical_accuracy: 0.3672 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.2003 - categorical_accuracy: 0.4702\n",
            "Epoch 8: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00008-1.20033-0.47024-1.81514-0.31250.h5\n",
            "21/21 [==============================] - 212s 11s/step - loss: 1.2003 - categorical_accuracy: 0.4702 - val_loss: 1.8151 - val_categorical_accuracy: 0.3125 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.1272 - categorical_accuracy: 0.5179\n",
            "Epoch 9: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00009-1.12723-0.51786-2.11647-0.29688.h5\n",
            "21/21 [==============================] - 222s 11s/step - loss: 1.1272 - categorical_accuracy: 0.5179 - val_loss: 2.1165 - val_categorical_accuracy: 0.2969 - lr: 5.0000e-04\n",
            "Epoch 10/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.1391 - categorical_accuracy: 0.5000\n",
            "Epoch 10: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00010-1.13906-0.50000-2.18634-0.27344.h5\n",
            "21/21 [==============================] - 211s 11s/step - loss: 1.1391 - categorical_accuracy: 0.5000 - val_loss: 2.1863 - val_categorical_accuracy: 0.2734 - lr: 5.0000e-04\n",
            "Epoch 11/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.1318 - categorical_accuracy: 0.5208\n",
            "Epoch 11: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00011-1.13176-0.52083-2.17216-0.29688.h5\n",
            "21/21 [==============================] - 206s 10s/step - loss: 1.1318 - categorical_accuracy: 0.5208 - val_loss: 2.1722 - val_categorical_accuracy: 0.2969 - lr: 5.0000e-04\n",
            "Epoch 12/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.1470 - categorical_accuracy: 0.5298\n",
            "Epoch 12: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00012-1.14697-0.52976-2.20980-0.30469.h5\n",
            "21/21 [==============================] - 225s 11s/step - loss: 1.1470 - categorical_accuracy: 0.5298 - val_loss: 2.2098 - val_categorical_accuracy: 0.3047 - lr: 2.5000e-04\n",
            "Epoch 13/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.0983 - categorical_accuracy: 0.5402\n",
            "Epoch 13: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00013-1.09830-0.54018-2.56883-0.25781.h5\n",
            "21/21 [==============================] - 206s 10s/step - loss: 1.0983 - categorical_accuracy: 0.5402 - val_loss: 2.5688 - val_categorical_accuracy: 0.2578 - lr: 2.5000e-04\n",
            "Epoch 14/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.0989 - categorical_accuracy: 0.5045\n",
            "Epoch 14: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00014-1.09888-0.50446-2.49511-0.25781.h5\n",
            "21/21 [==============================] - 207s 10s/step - loss: 1.0989 - categorical_accuracy: 0.5045 - val_loss: 2.4951 - val_categorical_accuracy: 0.2578 - lr: 2.5000e-04\n",
            "Epoch 15/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.0652 - categorical_accuracy: 0.5521\n",
            "Epoch 15: saving model to C:\\Temp\\RNN\\model_init_2024-03-0518_28_54.709195\\model-00015-1.06515-0.55208-2.52690-0.25000.h5\n",
            "21/21 [==============================] - 217s 11s/step - loss: 1.0652 - categorical_accuracy: 0.5521 - val_loss: 2.5269 - val_categorical_accuracy: 0.2500 - lr: 1.2500e-04\n"
          ]
        }
      ],
      "source": [
        "train_generator = generator(train_path, train_doc, batch_size, img_idx, image_height, image_width)\n",
        "val_generator = generator(val_path, val_doc, batch_size, img_idx, image_height, image_width)\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "\n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "\n",
        "filepath = model_path_prefix + model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-5) # write the REducelronplateau code here\n",
        "callbacks_list = [checkpoint, LR]\n",
        "\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1\n",
        "\n",
        "history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n",
        "                    callbacks=callbacks_list, validation_data=val_generator,\n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <font color='blue'>2.6.3 Accuracy & Remarks</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>Accuracy</b>:\n",
        "- Training: 0.38\n",
        "- Validation: 0.51\n",
        "\n",
        "<b>Remarks:</b>\n",
        "- Training and Validation Accuracies are least of all models, not acceptable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <font color='blue'>2.6.4 Next Actions</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we already have some good performing models, will choose one from those"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <font color='blue'>3. Conclusion & Final Selection</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Selected the best model from Model  4 with,\n",
        "- <b>Training Accuracy: </b>0.89\n",
        "- <b>Validation Accuracy: </b>0.82\n",
        "- <b>Batch Size: </b>32\n",
        "- <b>Frames: </b>10\n",
        "- <b>Image Height: </b>100\n",
        "- <b>Image Width: </b>100\n",
        "- <b>Drop out: </b>Yes, 0.5\n",
        "- <b>Batch Normalization: </b>Yes\n",
        "- <b>Layers: </b>32 > 64 > 128 >> 256 >> 5\n",
        "- <b>Model File Name: </b>model-00012-0.27254-0.89347-0.77396-0.82031.h5\n",
        "- <b>Model File Size: </b>57.2 MB\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
